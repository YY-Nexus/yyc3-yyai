// é«˜çº§è¯­éŸ³è®¾ç½®ç³»ç»Ÿ - æ”¯æŒè‡ªå®šä¹‰è¯­éŸ³ä¸Šä¼ ä¸å­¦ç§‘æ™ºèƒ½åŒ¹é…
export interface VoiceSettings {
  voiceType: "male" | "female" | "child" | "custom"
  speed: "slow" | "normal" | "fast"
  tone: "calm" | "lively" | "composed"
  customVoiceUrl?: string
  customVoiceName?: string
  enabled: boolean
  syncWithText: boolean // è¯­éŸ³ä¸æ–‡æœ¬ä¸¥æ ¼åŒæ­¥
  autoAdjustBySubject: boolean // æ ¹æ®å­¦ç§‘è‡ªåŠ¨è°ƒæ•´
}

export interface VoiceControl {
  isPlaying: boolean
  isPaused: boolean
  currentTime: number
  duration: number
  currentTextIndex: number // å½“å‰æ’­æ”¾åˆ°çš„æ–‡æœ¬ç´¢å¼•
}

export interface CustomVoiceData {
  id: string
  name: string
  url: string
  uploadDate: Date
  duration: number
  fileSize: number
}

export const DEFAULT_VOICE_SETTINGS: VoiceSettings = {
  voiceType: "female",
  speed: "normal",
  tone: "calm",
  enabled: true,
  syncWithText: true,
  autoAdjustBySubject: true,
}

// é€Ÿåº¦æ˜ å°„ï¼ˆæ›´ç²¾ç»†çš„æ§åˆ¶ï¼‰
export const SPEED_MAP = {
  slow: 0.7,
  normal: 1.0,
  fast: 1.3,
}

// éŸ³è°ƒæ˜ å°„
export const PITCH_MAP = {
  calm: 0.9,
  lively: 1.2,
  composed: 1.0,
}

// è¯­éŸ³ç±»å‹é…ç½®ï¼ˆæ”¯æŒå¤šç§ä¸­æ–‡è¯­éŸ³ï¼‰
export const VOICE_TYPE_CONFIG = {
  male: {
    name: "ç”·å£°",
    icon: "ğŸ‘¨",
    pitch: 0.85,
    fallbackVoices: [
      "Microsoft Yunyang Online (Natural) - Chinese (Mainland)",
      "Microsoft Yunjian Online (Natural) - Chinese (Mainland)",
      "zh-CN-YunyangNeural",
      "zh-CN",
    ],
  },
  female: {
    name: "å¥³å£°",
    icon: "ğŸ‘©",
    pitch: 1.0,
    fallbackVoices: [
      "Microsoft Xiaoxiao Online (Natural) - Chinese (Mainland)",
      "Microsoft Xiaoyi Online (Natural) - Chinese (Mainland)",
      "zh-CN-XiaoxiaoNeural",
      "zh-CN",
    ],
  },
  child: {
    name: "ç«¥å£°",
    icon: "ğŸ‘¶",
    pitch: 1.3,
    fallbackVoices: [
      "Microsoft Yunxi Online (Natural) - Chinese (Mainland)",
      "Microsoft Xiaomo Online (Natural) - Chinese (Mainland)",
      "zh-CN-YunxiNeural",
      "zh-CN",
    ],
  },
  custom: {
    name: "è‡ªå®šä¹‰",
    icon: "ğŸ¤",
    pitch: 1.0,
    fallbackVoices: [],
  },
}

// å­¦ç§‘æ™ºèƒ½è¯­éŸ³åŒ¹é…
export const SUBJECT_VOICE_PROFILES = {
  chinese: {
    voiceType: "female" as const,
    tone: "calm" as const,
    speed: "normal" as const,
    description: "è¯­æ–‡å­¦ä¹ ä½¿ç”¨å¹³é™å¥³å£°ï¼Œå¸®åŠ©ç†è§£æ–‡å­¦ä¹‹ç¾",
  },
  math: {
    voiceType: "female" as const,
    tone: "composed" as const,
    speed: "normal" as const,
    description: "æ•°å­¦å­¦ä¹ ä½¿ç”¨æ²‰ç¨³å¥³å£°ï¼ŒåŸ¹å…»é€»è¾‘æ€ç»´",
  },
  "math-competition": {
    voiceType: "child" as const,
    tone: "lively" as const,
    speed: "fast" as const,
    description: "å¥¥æ•°ç«èµ›ä½¿ç”¨æ´»æ³¼ç«¥å£°ï¼Œæ¿€å‘å­¦ä¹ å…´è¶£",
  },
  english: {
    voiceType: "female" as const,
    tone: "lively" as const,
    speed: "normal" as const,
    description: "è‹±è¯­å­¦ä¹ ä½¿ç”¨æ´»æ³¼å¥³å£°ï¼Œå¢å¼ºè¯­è¨€æ„ŸçŸ¥",
  },
  science: {
    voiceType: "male" as const,
    tone: "composed" as const,
    speed: "normal" as const,
    description: "ç§‘å­¦æ¢ç´¢ä½¿ç”¨æ²‰ç¨³ç”·å£°ï¼Œä¼ é€’ç§‘å­¦ä¸¥è°¨",
  },
}

// åˆ›å»ºè¯­éŸ³åˆæˆå®ä¾‹ï¼ˆæ”¯æŒWeb Speech APIï¼‰
export function createSpeechSynthesis(text: string, settings: VoiceSettings): SpeechSynthesisUtterance {
  const utterance = new SpeechSynthesisUtterance(text)

  utterance.lang = "zh-CN"
  utterance.rate = SPEED_MAP[settings.speed]
  utterance.pitch = PITCH_MAP[settings.tone] * (VOICE_TYPE_CONFIG[settings.voiceType]?.pitch || 1.0)
  utterance.volume = 1.0

  // å°è¯•è®¾ç½®ç‰¹å®šè¯­éŸ³
  const voices = speechSynthesis.getVoices()
  const voiceConfig = VOICE_TYPE_CONFIG[settings.voiceType]

  if (voiceConfig && voiceConfig.fallbackVoices.length > 0) {
    for (const voiceName of voiceConfig.fallbackVoices) {
      const targetVoice = voices.find((voice) => voice.name.includes(voiceName) || voice.lang.includes(voiceName))
      if (targetVoice) {
        utterance.voice = targetVoice
        break
      }
    }
  }

  return utterance
}

// åˆ›å»ºè‡ªå®šä¹‰è¯­éŸ³æ’­æ”¾å™¨ï¼ˆä½¿ç”¨Web Audio APIï¼‰
export class CustomVoicePlayer {
  private audioContext: AudioContext | null = null
  private sourceNode: AudioBufferSourceNode | null = null
  private audioBuffer: AudioBuffer | null = null
  private startTime = 0
  private pauseTime = 0
  private isPlaying = false
  private isPaused = false

  constructor() {
    if (typeof window !== "undefined") {
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    }
  }

  async loadAudio(url: string): Promise<void> {
    if (!this.audioContext) throw new Error("AudioContext not available")

    try {
      const response = await fetch(url)
      const arrayBuffer = await response.arrayBuffer()
      this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer)
    } catch (error) {
      console.error("åŠ è½½éŸ³é¢‘å¤±è´¥:", error)
      throw error
    }
  }

  play(offset = 0): void {
    if (!this.audioContext || !this.audioBuffer) return

    if (this.isPaused) {
      // ä»æš‚åœä½ç½®ç»§ç»­æ’­æ”¾
      this.resume()
      return
    }

    // åœæ­¢å½“å‰æ’­æ”¾
    this.stop()

    // åˆ›å»ºæ–°çš„æºèŠ‚ç‚¹
    this.sourceNode = this.audioContext.createBufferSource()
    this.sourceNode.buffer = this.audioBuffer
    this.sourceNode.connect(this.audioContext.destination)

    // è®°å½•å¼€å§‹æ—¶é—´
    this.startTime = this.audioContext.currentTime - offset
    this.sourceNode.start(0, offset)

    this.isPlaying = true
    this.isPaused = false
  }

  pause(): void {
    if (!this.audioContext || !this.isPlaying || this.isPaused) return

    this.pauseTime = this.audioContext.currentTime - this.startTime
    this.stop()
    this.isPaused = true
    this.isPlaying = false
  }

  resume(): void {
    if (!this.isPaused) return

    this.play(this.pauseTime)
    this.isPaused = false
  }

  stop(): void {
    if (this.sourceNode) {
      try {
        this.sourceNode.stop()
      } catch (e) {
        // å·²ç»åœæ­¢çš„èŠ‚ç‚¹ä¼šæŠ›å‡ºé”™è¯¯ï¼Œå¿½ç•¥
      }
      this.sourceNode.disconnect()
      this.sourceNode = null
    }
    this.isPlaying = false
    this.isPaused = false
    this.pauseTime = 0
  }

  getCurrentTime(): number {
    if (!this.audioContext) return 0

    if (this.isPaused) {
      return this.pauseTime
    }

    if (this.isPlaying) {
      return this.audioContext.currentTime - this.startTime
    }

    return 0
  }

  getDuration(): number {
    return this.audioBuffer?.duration || 0
  }

  seek(time: number): void {
    const wasPlaying = this.isPlaying
    this.stop()
    if (wasPlaying) {
      this.play(time)
    } else {
      this.pauseTime = time
      this.isPaused = true
    }
  }

  getState(): { isPlaying: boolean; isPaused: boolean } {
    return {
      isPlaying: this.isPlaying,
      isPaused: this.isPaused,
    }
  }

  dispose(): void {
    this.stop()
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
    this.audioBuffer = null
  }
}

// ä¿å­˜è¯­éŸ³è®¾ç½®åˆ°æœ¬åœ°å­˜å‚¨
export function saveVoiceSettings(settings: VoiceSettings): void {
  if (typeof window !== "undefined") {
    localStorage.setItem("voiceSettings", JSON.stringify(settings))
  }
}

// ä»æœ¬åœ°å­˜å‚¨åŠ è½½è¯­éŸ³è®¾ç½®
export function loadVoiceSettings(): VoiceSettings {
  if (typeof window !== "undefined") {
    const saved = localStorage.getItem("voiceSettings")
    if (saved) {
      try {
        return JSON.parse(saved)
      } catch (e) {
        console.error("è§£æè¯­éŸ³è®¾ç½®å¤±è´¥:", e)
      }
    }
  }
  return DEFAULT_VOICE_SETTINGS
}

// ä¿å­˜è‡ªå®šä¹‰è¯­éŸ³æ•°æ®
export function saveCustomVoice(voiceData: CustomVoiceData): void {
  if (typeof window !== "undefined") {
    const voices = loadCustomVoices()
    voices.push(voiceData)
    localStorage.setItem("customVoices", JSON.stringify(voices))
  }
}

// åŠ è½½æ‰€æœ‰è‡ªå®šä¹‰è¯­éŸ³
export function loadCustomVoices(): CustomVoiceData[] {
  if (typeof window !== "undefined") {
    const saved = localStorage.getItem("customVoices")
    if (saved) {
      try {
        return JSON.parse(saved)
      } catch (e) {
        console.error("è§£æè‡ªå®šä¹‰è¯­éŸ³å¤±è´¥:", e)
      }
    }
  }
  return []
}

// åˆ é™¤è‡ªå®šä¹‰è¯­éŸ³
export function deleteCustomVoice(voiceId: string): void {
  if (typeof window !== "undefined") {
    const voices = loadCustomVoices()
    const filtered = voices.filter((v) => v.id !== voiceId)
    localStorage.setItem("customVoices", JSON.stringify(filtered))
  }
}

// æ ¹æ®å­¦ç§‘è‡ªåŠ¨è°ƒæ•´è¯­éŸ³è®¾ç½®
export function getVoiceSettingsForSubject(subject: string, currentSettings: VoiceSettings): Partial<VoiceSettings> {
  const profile = SUBJECT_VOICE_PROFILES[subject as keyof typeof SUBJECT_VOICE_PROFILES]

  if (!profile || !currentSettings.autoAdjustBySubject) {
    return {}
  }

  return {
    voiceType: profile.voiceType,
    tone: profile.tone,
    speed: profile.speed,
  }
}

// æ–‡æœ¬åˆ†æ®µç”¨äºåŒæ­¥æ’­æ”¾
export function segmentTextForSync(text: string): string[] {
  // æŒ‰å¥å­åˆ†æ®µï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
  const segments = text.split(/([ã€‚ï¼ï¼Ÿ.!?;ï¼›]+)/).filter((s) => s.trim().length > 0)

  // åˆå¹¶æ ‡ç‚¹ç¬¦å·ä¸å‰é¢çš„æ–‡æœ¬
  const result: string[] = []
  for (let i = 0; i < segments.length; i++) {
    if (segments[i].match(/^[ã€‚ï¼ï¼Ÿ.!?;ï¼›]+$/)) {
      if (result.length > 0) {
        result[result.length - 1] += segments[i]
      }
    } else {
      result.push(segments[i])
    }
  }

  return result
}
